// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.10 (swiftlang-5.10.0.13 clang-1500.3.9.4)
// swift-module-flags: -target x86_64-apple-ios12.0-simulator -enable-objc-interop -enable-library-evolution -static -O -enable-bare-slash-regex -module-name MediaPipeTasksGenAI
import Foundation
import MediaPipeTasksGenAIC
import Swift
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
@objc(MPPLLMInference) final public class LlmInference : ObjectiveC.NSObject {
  @objc public init(options: MediaPipeTasksGenAI.LlmInference.Options) throws
  @objc convenience public init(modelPath: Swift.String) throws
  @objc final public func generateResponse(inputText: Swift.String) throws -> Swift.String
  @objc final public func generateResponseAsync(inputText: Swift.String, progress: @escaping (_ partialResponse: Swift.String?, _ error: (any Swift.Error)?) -> Swift.Void, completion: @escaping (() -> Swift.Void)) throws
  @available(iOS 13, macOS 10.15, tvOS 13, watchOS 6, *)
  final public func generateResponseAsync(inputText: Swift.String) -> _Concurrency.AsyncThrowingStream<Swift.String, any Swift.Error>
  @objc deinit
}
extension MediaPipeTasksGenAI.LlmInference {
  @objc(MPPLLMInferenceOptions) final public class Options : ObjectiveC.NSObject {
    @objc final public var modelPath: Swift.String
    @objc final public var maxTokens: Swift.Int
    @objc final public var maxTopk: Swift.Int
    @objc final public var supportedLoraRanks: [Swift.Int]
    @objc final public var activationDataType: MediaPipeTasksGenAI.LlmInference.ActivationDataType
    @objc public init(modelPath: Swift.String)
    @objc deinit
  }
  @objc(MPPLLMInferenceActivationDataType) public enum ActivationDataType : Swift.Int {
    case `default` = 0
    case float32 = 1
    case float16 = 2
    case int16 = 3
    case int8 = 4
    public init?(rawValue: Swift.Int)
    public typealias RawValue = Swift.Int
    public var rawValue: Swift.Int {
      get
    }
  }
}
extension MediaPipeTasksGenAI.LlmInference {
  @_hasMissingDesignatedInitializers @objc(MPPLLMInferenceSession) final public class Session : ObjectiveC.NSObject {
    @objc public init(llmInference: MediaPipeTasksGenAI.LlmInference, options: MediaPipeTasksGenAI.LlmInference.Session.Options) throws
    @objc convenience public init(llmInference: MediaPipeTasksGenAI.LlmInference) throws
    @objc final public func addQueryChunk(inputText: Swift.String) throws
    @objc final public func generateResponse() throws -> Swift.String
    @objc final public func generateResponseAsync(progress: @escaping (_ partialResponse: Swift.String?, _ error: (any Swift.Error)?) -> Swift.Void, completion: @escaping (() -> Swift.Void)) throws
    @available(iOS 13, macOS 10.15, tvOS 13, watchOS 6, *)
    final public func generateResponseAsync() -> _Concurrency.AsyncThrowingStream<Swift.String, any Swift.Error>
    final public func sizeInTokens(text: Swift.String) throws -> Swift.Int
    final public func clone() throws -> MediaPipeTasksGenAI.LlmInference.Session
    @objc deinit
  }
}
extension MediaPipeTasksGenAI.LlmInference.Session {
  @_inheritsConvenienceInitializers @objc(MPPLLMInferenceSessionOptions) final public class Options : ObjectiveC.NSObject {
    @objc final public var topk: Swift.Int
    @objc final public var topp: Swift.Float
    @objc final public var temperature: Swift.Float
    @objc final public var randomSeed: Swift.Int
    @objc final public var loraPath: Swift.String?
    @objc override dynamic public init()
    @objc deinit
  }
}
public enum GenAiInferenceError : Swift.Error {
  case invalidResponse
  case illegalMethodCall
  case failedToComputeSizeInTokens(Swift.String?)
  case failedToInitializeSession(Swift.String?)
  case failedToInitializeEngine(Swift.String?)
  case failedToAddQueryToSession(Swift.String, Swift.String?)
  case failedToCloneSession(Swift.String?)
}
extension MediaPipeTasksGenAI.GenAiInferenceError : Foundation.LocalizedError {
  public var errorDescription: Swift.String? {
    get
  }
}
extension MediaPipeTasksGenAI.GenAiInferenceError : Foundation.CustomNSError {
  public static var errorDomain: Swift.String {
    get
  }
  public var errorCode: Swift.Int {
    get
  }
}
extension MediaPipeTasksGenAI.LlmInference.ActivationDataType : Swift.Equatable {}
extension MediaPipeTasksGenAI.LlmInference.ActivationDataType : Swift.Hashable {}
extension MediaPipeTasksGenAI.LlmInference.ActivationDataType : Swift.RawRepresentable {}
